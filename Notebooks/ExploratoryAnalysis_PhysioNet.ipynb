{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset List: \n",
    "\n",
    "1. PhysioNet 2021 Challenge\n",
    "\n",
    "```\n",
    "    Data Sources: \n",
    "    \n",
    "    CPSC Database and CPSC-Extra Database\n",
    "    INCART Database\n",
    "    PTB and PTB-XL Database\n",
    "    The Georgia 12-lead ECG Challenge (G12EC) Database\n",
    "    Augmented Undisclosed Database\n",
    "    Chapman-Shaoxing and Ningbo Database\n",
    "    The University of Michigan (UMich) Database\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PhysioNet 2021 Challenge\n",
    "\n",
    "The training data contains twelve-lead ECGs. The validation and test data contains twelve-lead, six-lead, four-lead, three-lead, and two-lead ECGs:\n",
    "\n",
    "1. Twelve leads: I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6\n",
    "2. Six leads: I, II, III, aVR, aVL, aVF\n",
    "3. Four leads: I, II, III, V2\n",
    "4. Three leads: I, II, V2\n",
    "5. Two leads: I, II\n",
    "\n",
    "Each ECG recording has one or more labels that describe cardiac abnormalities (and/or a normal sinus rhythm).\n",
    "\n",
    "The Challenge data include annotated twelve-lead ECG recordings from six sources in four countries across three continents. These databases include over 100,000 twelve-lead ECG recordings with over 88,000 ECGs shared publicly as training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a header file A0001.hea may have the following contents:\n",
    "\n",
    "```\n",
    "    A0001 12 500 7500\n",
    "    A0001.mat 16+24 1000/mV 16 0 28 -1716 0 I\n",
    "    A0001.mat 16+24 1000/mV 16 0 7 2029 0 II\n",
    "    A0001.mat 16+24 1000/mV 16 0 -21 3745 0 III\n",
    "    A0001.mat 16+24 1000/mV 16 0 -17 3680 0 aVR\n",
    "    A0001.mat 16+24 1000/mV 16 0 24 -2664 0 aVL\n",
    "    A0001.mat 16+24 1000/mV 16 0 -7 -1499 0 aVF\n",
    "    A0001.mat 16+24 1000/mV 16 0 -290 390 0 V1\n",
    "    A0001.mat 16+24 1000/mV 16 0 -204 157 0 V2\n",
    "    A0001.mat 16+24 1000/mV 16 0 -96 -2555 0 V3\n",
    "    A0001.mat 16+24 1000/mV 16 0 -112 49 0 V4\n",
    "    A0001.mat 16+24 1000/mV 16 0 -596 -321 0 V5\n",
    "    A0001.mat 16+24 1000/mV 16 0 -16 -3112 0 V6\n",
    "    #Age: 74\n",
    "    #Sex: Male\n",
    "    #Dx: 426783006\n",
    "    #Rx: Unknown\n",
    "    #Hx: Unknown\n",
    "    #Sx: Unknown\n",
    "```\n",
    "\n",
    "From the first line of the file:\n",
    "- We see that the recording number is A0001, and the recording file is A0001.mat. \n",
    "- The recording has 12 leads, each recorded at a 500 Hz sampling frequency, and contains 7500 samples. \n",
    "- From the next 12 lines of the file (one for each lead), we see that each signal:\n",
    "    - Was written at 16 bits with an offset of 24 bits\n",
    "    - The floating point number (analog-to-digital converter (ADC) units per physical unit) is 1000/mV \n",
    "    - The resolution of the analog-to-digital converter (ADC) used to digitize the signal is 16 bits, and the baseline value corresponding to 0 physical units is 0. \n",
    "    - The first value of the signal (-1716, etc.), the checksum (0, etc.), and the lead name (I, etc.) are the last three entries of each of these lines. \n",
    "- From the final 6 lines, we see that the patient is:\n",
    "    - A 74-year-old male \n",
    "    - With a diagnosis (Dx) of 426783006, which is the **SNOMED-CT code** for sinus rhythm. \n",
    "    - The medical prescription (Rx), history (Hx), and symptom or surgery (Sx) are unknown. \n",
    "\n",
    "- Please visit WFDB header format for more information on the header file and variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Source Information\n",
    "\n",
    "1. CPSC Database and CPSC-Extra Database\n",
    "\n",
    "- Together, these databases contain 13,256 ECGs (10,330 ECGs shared as training data, 1,463 retained as validation data, and 1,463 retained as test data).\n",
    "- Each recording is between 6 and 144 seconds long with a sampling frequency of 500 Hz.\n",
    "- Per HIPAA guidelines ages over 89 are not provided for these datasets herein.\n",
    "- cpsc_2018, 6,877 recordings\n",
    "- cpsc_2018_extra, 3,453 recordings\n",
    "\n",
    "2. INCART (st_petersburg_incart) Database\n",
    "\n",
    "- This source contains 74 annotated ECGs (all shared as training data) extracted from 32 Holter monitor recordings. \n",
    "- Each recording is 30 minutes long with a sampling frequency of 257 Hz.\n",
    "\n",
    "3. PTB and PTB-XL Database\n",
    "\n",
    "- The source contains 22,353 ECGs (all shared as training data). \n",
    "- Each recording is between 10 and 120 seconds long with a sampling frequency of either 500 or 1,000 Hz.\n",
    "- PTB, 516 recordings\n",
    "- PTB-XL, 21,837 recordings\n",
    "\n",
    "4. Georgia 12-lead ECG Challenge (G12EC) Database\n",
    "\n",
    "- This source contains 20,672 ECGs (10,344 ECGs shared as training data, 5,167 retained as validation data, and 5,161 retained as test data). \n",
    "- Each recording is between 5 and 10 seconds long with a sampling frequency of 500 Hz.\n",
    "\n",
    "5. Shaoxing Peopleâ€™s Hospital (Chapman-Shaoxing) and Ningbo First Hospital (Ningbo) Database  \n",
    "\n",
    "- This source contains 45,152 ECGS (all shared as training data). \n",
    "- Each recording is 10 seconds long with a sampling frequency of 500 Hz\n",
    "- chapman-shaoxing, 10,247 recordings\n",
    "- ningbo, 34,905 recordings\n",
    "\n",
    "NOTE: Under each dataset folder the files are grouped into subfolders with up to 1000 records per subfolder. These subfolders are named as g# where the # starts at 1. Once 1000 records are allocated to a folder a new folder is started with the # incremented by one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration & Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Matlab/WFDB files\n",
    "import scipy.io as sio\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['helper_functions.py', 'helper_function_tests.py', '__init__.py']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('C:/Users/navme/Desktop/ECG_Project/PyFiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('C:/Users/navme/Desktop/ECG_Project/PyFiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper functions\n",
    "import helper_functions as hf\n",
    "import helper_function_tests as hft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PhysioNet_PATH = f'C:/Users/navme/Desktop/ECG_Thesis_Local/PhysioNet-2021-Challenge/physionet.org/files/challenge-2021/1.0.3/training'\n",
    "PhysioNet_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(PhysioNet_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the file paths in the PhysioNet directory\n",
    "physionet_file_PATHS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(PhysioNet_PATH):\n",
    "    file_path = os.path.join(PhysioNet_PATH, file)\n",
    "    file_path = file_path.replace('\\\\', '/')\n",
    "    physionet_file_PATHS.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physionet_file_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(physionet_file_PATHS[1]))\n",
    "print(physionet_file_PATHS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physionet_file_PATHS = [path for path in physionet_file_PATHS if \"index.html\" not in path]\n",
    "physionet_file_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physionet_file_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datasets = ['ptb', 'ptb-xl']\n",
    "\n",
    "for file in os.listdir(PhysioNet_PATH):\n",
    "    file_path = os.path.join(PhysioNet_PATH, file)\n",
    "    file_path = file_path.replace('\\\\', '/')\n",
    "    if file not in validation_datasets:\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check an example of what the g1 folder of chapman_shaoxing database looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapman_shaoxing_g1 = os.path.join(physionet_file_PATHS[0], os.listdir(physionet_file_PATHS[0])[0])\n",
    "chapman_shaoxing_g1 = chapman_shaoxing_g1.replace('\\\\', '/')\n",
    "chapman_shaoxing_g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapman_shaoxing_g1_hea = []\n",
    "chapman_shaoxing_g1_mat = []\n",
    "\n",
    "for file in os.listdir(chapman_shaoxing_g1): \n",
    "    if file.endswith('.hea'):\n",
    "        chapman_shaoxing_g1_hea.append(file)\n",
    "    elif file.endswith('.mat'):\n",
    "        chapman_shaoxing_g1_mat.append(file)\n",
    "\n",
    "len(chapman_shaoxing_g1_hea), len(chapman_shaoxing_g1_mat), len(os.listdir(chapman_shaoxing_g1))  # len(os.listdir(chapman_shaoxing_g1) contains RECORDS and index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(physionet_file_PATHS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path_hea = []\n",
    "test_data_path_mat = []\n",
    "test_data_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in physionet_file_PATHS:\n",
    "    for sub_folder in os.listdir(path):\n",
    "        sub_folder_path = os.path.join(path, sub_folder)\n",
    "        sub_folder_path = sub_folder_path.replace('\\\\', '/')\n",
    "        if sub_folder.endswith('index.html'):\n",
    "            test_data_indices.append(sub_folder_path)\n",
    "        else:\n",
    "            if os.path.isdir(sub_folder_path):\n",
    "                for file in os.listdir(sub_folder_path):\n",
    "                    if file.endswith('.hea'):\n",
    "                        file_path = os.path.join(sub_folder_path, file)\n",
    "                        file_path = file_path.replace('\\\\', '/')\n",
    "                        test_data_path_hea.append(file_path)\n",
    "                    elif file.endswith('.mat'):\n",
    "                        file_path = os.path.join(sub_folder_path, file)\n",
    "                        file_path = file_path.replace('\\\\', '/')\n",
    "                        test_data_path_mat.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data_path_hea), len(test_data_path_mat), len(test_data_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hea_file_path = test_data_path_hea[10]\n",
    "\n",
    "with open(hea_file_path, 'r') as f:\n",
    "    contents = f.read()\n",
    "\n",
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hea_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file_path = test_data_path_mat[10]\n",
    "\n",
    "data = sio.loadmat(mat_file_path)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(12, 8))\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.plot(data['val'][i])\n",
    "    ax.set_xlabel('Sample')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.set_title(f'Lead {i+1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysioNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path, train=False):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.dataset_path = [path for path in self.dataset_path if \"index.html\" not in path]\n",
    "        self.train = train\n",
    "        self.file_list = os.listdir(dataset_path)\n",
    "        self._hea_files = []\n",
    "        self._mat_files = []\n",
    "        self._indices_files = []\n",
    "\n",
    "        self.file_PATHS = []  # Directory to main database folders\n",
    "        self.data_files = []  # Directory to data files\n",
    "\n",
    "        # Validation Case: PTB Databases only\n",
    "        if self.train == False:\n",
    "            validation_datasets = ['ptb', 'ptb-xl']\n",
    "            for file in os.listdir(dataset_path):\n",
    "                if file in validation_datasets:\n",
    "                    file_path = os.path.join(dataset_path, file)\n",
    "                    file_path = file_path.replace('\\\\', '/')\n",
    "                    self.file_PATHS.append(file_path)\n",
    "\n",
    "        # Training Case: All Databases excluding PTB\n",
    "        else:\n",
    "            validation_datasets = ['ptb', 'ptb-xl']\n",
    "            for file in os.listdir(dataset_path):\n",
    "                if file not in validation_datasets:\n",
    "                    file_path = os.path.join(dataset_path, file)\n",
    "                    file_path = file_path.replace('\\\\', '/')\n",
    "                    self.file_PATHS.append(file_path)\n",
    "\n",
    "        for path in self.file_PATHS:\n",
    "            if os.path.isdir(path):\n",
    "                for sub_folder in os.listdir(path):\n",
    "                    sub_folder_path = os.path.join(path, sub_folder)\n",
    "                    sub_folder_path = sub_folder_path.replace('\\\\', '/')\n",
    "                    \n",
    "                    # Ignore index.html files\n",
    "                    if sub_folder_path.endswith('index.html'):\n",
    "                        self._indices_files.append(sub_folder_path)\n",
    "                    else:\n",
    "                        if os.path.isdir(sub_folder_path):\n",
    "                            for file in os.listdir(sub_folder_path):\n",
    "                                # Get all .hea files\n",
    "                                if file.endswith('.hea'):\n",
    "                                    file_path = os.path.join(sub_folder_path, file)\n",
    "                                    file_path = file_path.replace('\\\\', '/')\n",
    "                                    self._hea_files.append(file_path)\n",
    "                                # Get all .mat files\n",
    "                                elif file.endswith('.mat'):\n",
    "                                    file_path = os.path.join(sub_folder_path, file)\n",
    "                                    file_path = file_path.replace('\\\\', '/')\n",
    "                                    self._mat_files.append(file_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 1. Get .hea file\n",
    "        hea_file_path = self._hea_files[index]\n",
    "        with open(hea_file_path, 'r') as f:\n",
    "            header = print(f.read())\n",
    "\n",
    "        # 2. Get .mat file\n",
    "        mat_file_path = self._mat_files[index]\n",
    "        twelve_lead_ecg = sio.loadmat(mat_file_path)\n",
    "        \n",
    "        return header, twelve_lead_ecg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_PATHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
