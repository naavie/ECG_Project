{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Thesis Topic: “Zero-shot classification of ECG signals using CLIP-like model”.\n",
    "\n",
    "**For example: Train on PBT-XL:**\n",
    "\n",
    "- Text Encoder: ClinicalBERT (trained on diagnoses of ECG signal to obtain corresponding embeddings)\n",
    "- Image Encoder: 1D-CNN (used to encode ECG signal to obtain signal embeddings)\n",
    "\n",
    "- Experiment A): Baseline: We can take only the name of the class. For example, take “Myocardial Infarction” as a text. We should exclude some classes from training and after training is completed, the CLIP-like model can be tested on these excluded classes.\n",
    "    - Next, we get embeddings of text from ClinicalBERT and train the ECG encoder with contrastive loss.\n",
    "\n",
    "- Experiment B): Same as Experiment A but instead of testing on the same dataset/classes, we would test on other datasets containing different classes.\n",
    "\n",
    "**Evaluation metrics:**\n",
    "- Main: AUC-ROC, average_precison_score,\n",
    "- Optional: Specificity, Sensitivity, F1-score\n",
    "\n",
    "**Outcome:**\n",
    "- It’s possible to train CLIP-like models with freezed (or unchanged/not fine tuned for downstream tasks) text encoder\n",
    "- Training ECG encoders that are viable for representing different domains (within ECG modality) and previously unseen classes.\n",
    "- Training a CLIP-like model on ECGs has little novelty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import resample\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import ast\n",
    "import scipy.io as sio\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('C:/Users/navme/Desktop/ECG_Project/PyFiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ```PhysioNet_PATH```, we can create separate datasets for training, testing & validation.\n",
    "\n",
    "# Stage 1: Data Preprocessing\n",
    "\n",
    "- train_set (train & validation data)\n",
    "- test_set (test data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the SNOWMED-CT mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dx</th>\n",
       "      <th>SNOMEDCTCode</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>CPSC</th>\n",
       "      <th>CPSC_Extra</th>\n",
       "      <th>StPetersburg</th>\n",
       "      <th>PTB</th>\n",
       "      <th>PTB_XL</th>\n",
       "      <th>Georgia</th>\n",
       "      <th>Chapman_Shaoxing</th>\n",
       "      <th>Ningbo</th>\n",
       "      <th>Total</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atrial fibrillation</td>\n",
       "      <td>164889003</td>\n",
       "      <td>AF</td>\n",
       "      <td>1221</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1514</td>\n",
       "      <td>570</td>\n",
       "      <td>1780</td>\n",
       "      <td>0</td>\n",
       "      <td>5255</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atrial flutter</td>\n",
       "      <td>164890007</td>\n",
       "      <td>AFL</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>186</td>\n",
       "      <td>445</td>\n",
       "      <td>7615</td>\n",
       "      <td>8374</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Dx  SNOMEDCTCode Abbreviation  CPSC  CPSC_Extra  \\\n",
       "0  atrial fibrillation     164889003           AF  1221         153   \n",
       "1       atrial flutter     164890007          AFL     0          54   \n",
       "\n",
       "   StPetersburg  PTB  PTB_XL  Georgia  Chapman_Shaoxing  Ningbo  Total Notes  \n",
       "0             2   15    1514      570              1780       0   5255   NaN  \n",
       "1             0    1      73      186               445    7615   8374   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smowmed_mappings_path = convert_to_forward_slashes(r'C:\\Users\\navme\\Desktop\\ECG_Project\\Data\\SNOWMED-CT Codes\\combined_mappings.csv')\n",
    "\n",
    "# Load the SNOMED-CT mappings\n",
    "smowmed_mappings = pd.read_csv(smowmed_mappings_path)\n",
    "smowmed_mappings.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 'Dx' and 'SNOMEDCTCode' columns\n",
    "codes = smowmed_mappings[['Dx', 'SNOMEDCTCode']]\n",
    "\n",
    "# Set 'SNOWMEDCTCode' as the index\n",
    "codes.set_index('SNOMEDCTCode', inplace=True)\n",
    "\n",
    "# Convert the DataFrame into a dictionary\n",
    "codes_dict = codes['Dx'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(164889003, 'atrial fibrillation'),\n",
       " (164890007, 'atrial flutter'),\n",
       " (6374002, 'bundle branch block'),\n",
       " (426627000, 'bradycardia'),\n",
       " (733534002, 'complete left bundle branch block')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(codes_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated PhysioNetDataset Class \n",
    "\n",
    "- Update the ```PhysioNetDataset``` class such that instead of header_info --> return header_info['Dx']. Then convert the Dx code to string input for TextEncoder(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysioNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path, train=False):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.dataset_path = [path for path in self.dataset_path if \"index.html\" not in path]\n",
    "        self.train = train\n",
    "        self.file_list = os.listdir(dataset_path)\n",
    "        self._hea_files = []\n",
    "        self._mat_files = []\n",
    "        self._indices_files = []\n",
    "        self._hea_files_path = []\n",
    "        self._mat_files_path = []\n",
    "\n",
    "        self.file_PATHS = []  # Directory to main database folders\n",
    "        self.data_files = []  # Directory to data files\n",
    "\n",
    "        # Validation Case: PTB Databases only\n",
    "        if self.train == False:\n",
    "            validation_datasets = ['ptb', 'ptb-xl']\n",
    "            for file in os.listdir(dataset_path):\n",
    "                if file in validation_datasets:\n",
    "                    file_path = os.path.join(dataset_path, file)\n",
    "                    file_path = file_path.replace('\\\\', '/')\n",
    "                    self.file_PATHS.append(file_path)\n",
    "\n",
    "        # Training Case: All Databases excluding PTB\n",
    "        else:\n",
    "            validation_datasets = ['ptb', 'ptb-xl']\n",
    "            for file in os.listdir(dataset_path):\n",
    "                if file not in validation_datasets:\n",
    "                    file_path = os.path.join(dataset_path, file)\n",
    "                    file_path = file_path.replace('\\\\', '/')\n",
    "                    self.file_PATHS.append(file_path)\n",
    "\n",
    "        for path in self.file_PATHS:\n",
    "            if os.path.isdir(path):\n",
    "                for sub_folder in os.listdir(path):\n",
    "                    sub_folder_path = os.path.join(path, sub_folder)\n",
    "                    sub_folder_path = sub_folder_path.replace('\\\\', '/')\n",
    "\n",
    "                    # Ignore index.html files\n",
    "                    if sub_folder_path.endswith('index.html'):\n",
    "                        self._indices_files.append(sub_folder_path)\n",
    "                    else:\n",
    "                        if os.path.isdir(sub_folder_path):\n",
    "                            for file in os.listdir(sub_folder_path):\n",
    "                                # Get all .hea files\n",
    "                                if file.endswith('.hea'):\n",
    "                                    file_path = os.path.join(sub_folder_path, file)\n",
    "                                    file_path = file_path.replace('\\\\', '/')\n",
    "                                    self._hea_files.append(file_path)\n",
    "                                    self._hea_files_path.append(file_path)\n",
    "                                # Get all .mat files\n",
    "                                elif file.endswith('.mat'):\n",
    "                                    file_path = os.path.join(sub_folder_path, file)\n",
    "                                    file_path = file_path.replace('\\\\', '/')\n",
    "                                    self._mat_files.append(file_path)\n",
    "                                    self._mat_files_path.append(file_path)\n",
    "\n",
    "    def resample_ecg(self, data, old_freq, new_freq=128):\n",
    "        # Calculate the duration of the signal\n",
    "        duration = len(data) / old_freq\n",
    "\n",
    "        # Calculate the number of points in the resampled signal\n",
    "        num_points = int(np.round(duration * new_freq))\n",
    "\n",
    "        # Resample the signal\n",
    "        resampled_data = resample(data, num_points)\n",
    "\n",
    "        return resampled_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, slice):\n",
    "            start, stop, step = index.indices(len(self))\n",
    "            return [self[i] for i in range(start, stop, step)]\n",
    "        # 1. Get .hea file\n",
    "        hea_file_path = self._hea_files[index]\n",
    "        with open(hea_file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Parse header information\n",
    "        # Initialize header information\n",
    "        header_info = {\n",
    "            'recording_number': lines[0].split()[0],\n",
    "            'recording_file': lines[0].split()[0] + '.mat',\n",
    "            'num_leads': int(lines[0].split()[1]),\n",
    "            'sampling_frequency': int(lines[0].split()[2]),\n",
    "            'num_samples': int(lines[0].split()[3]),\n",
    "            'leads_info': [],\n",
    "            'age': None,\n",
    "            'sex': None,\n",
    "            'dx': None,\n",
    "            'rx': None,\n",
    "            'hx': None,\n",
    "            'sx': None,\n",
    "        }\n",
    "\n",
    "        # Parse header information\n",
    "        for line in lines:\n",
    "            if line.startswith('# Age:'):\n",
    "                age_str = line.split(':')[1].strip()\n",
    "                header_info['age'] = int(age_str) if age_str != 'NaN' else None\n",
    "            elif line.startswith('# Sex:'):\n",
    "                header_info['sex'] = line.split(':')[1].strip()\n",
    "            elif line.startswith('# Dx:'):\n",
    "                dx_codes = line.split(':')[1].strip().split(',')\n",
    "                dx_modalities = [codes_dict.get(int(code.strip()), code.strip()) for code in dx_codes]\n",
    "                header_info['dx'] = [codes_dict.get(int(code.strip()), code.strip()) for code in dx_codes]\n",
    "            elif line.startswith('# Rx:'):\n",
    "                header_info['rx'] = line.split(':')[1].strip()\n",
    "            elif line.startswith('# Hx:'):\n",
    "                header_info['hx'] = line.split(':')[1].strip()\n",
    "            elif line.startswith('# Sx:'):\n",
    "                header_info['sx'] = line.split(':')[1].strip()\n",
    "\n",
    "        for line in lines[1:header_info['num_leads']+1]:\n",
    "            adc_gain = line.split()[2].split('/')[0]\n",
    "            adc_gain = float(adc_gain.replace('(0)', ''))  # Remove '(0)' and convert to float\n",
    "            lead_info = {\n",
    "                'file': line.split()[0],\n",
    "                'adc_gain': adc_gain,\n",
    "                'units': line.split()[2].split('/')[1],\n",
    "                'adc_resolution': int(line.split()[3]),\n",
    "                'adc_zero': int(line.split()[4]),\n",
    "                'initial_value': int(line.split()[5]),\n",
    "                'checksum': int(line.split()[6]),\n",
    "                'lead_name': line.split()[7],\n",
    "            }\n",
    "            header_info['leads_info'].append(lead_info)\n",
    "\n",
    "        # 2. Get .mat file\n",
    "        twelve_lead_ecg = None\n",
    "        if index < len(self._mat_files):\n",
    "            mat_file_path = self._mat_files[index]\n",
    "            twelve_lead_ecg = sio.loadmat(mat_file_path)\n",
    "\n",
    "            # Resample the ECG to 128 Hz\n",
    "            for lead in twelve_lead_ecg:\n",
    "                twelve_lead_ecg[lead] = self.resample_ecg(twelve_lead_ecg[lead], old_freq=header_info['sampling_frequency'])\n",
    "        else:\n",
    "            print(f\"MAT file for index {index} does not exist.\")\n",
    "\n",
    "        # Return list of diagnoses and the np array of the 12-lead ECG\n",
    "        return dx_modalities, twelve_lead_ecg['val']\n",
    "\n",
    "    def plot_record(self, index):\n",
    "        mat_file_path = self._mat_files[index]\n",
    "        data = sio.loadmat(mat_file_path)\n",
    "        fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(20, 15))\n",
    "\n",
    "        for i, ax in enumerate(axs.flat):\n",
    "            ax.plot(data['val'][i], linewidth=0.5)\n",
    "            ax.set_xlabel('Sample')\n",
    "            ax.set_ylabel('Amplitude')\n",
    "            ax.set_title(f'Lead {i+1}')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._hea_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/navme/Desktop/ECG_Thesis_Local/PhysioNet-2021-Challenge/physionet.org/files/challenge-2021/1.0.3/training'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to training folder within PhysioNet dataset\n",
    "PhysioNet_PATH = f'C:/Users/navme/Desktop/ECG_Thesis_Local/PhysioNet-2021-Challenge/physionet.org/files/challenge-2021/1.0.3/training'\n",
    "PhysioNet_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65900, 22352)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = PhysioNetDataset(PhysioNet_PATH, train=True)\n",
    "test_set = PhysioNetDataset(PhysioNet_PATH, train=False)\n",
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```train_set``` can be split into ```current_train``` (85%) and ```current_val``` (15%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for the random number generator\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Get the length of the train_set\n",
    "length = len(train_set)\n",
    "\n",
    "# Calculate the lengths of the splits\n",
    "train_length = int(0.85 * length)\n",
    "val_length = length - train_length\n",
    "\n",
    "# Split the dataset\n",
    "current_train, current_val = random_split(train_set, [train_length, val_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56015, 9885)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current_train), len(current_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sinus tachycardia',\n",
       " 't wave inversion',\n",
       " 't wave abnormal',\n",
       " 'prolonged qt interval']"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diagnoses\n",
    "current_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-71.34097139, -66.61618625, -70.0758572 , ..., -52.92145257,\n",
       "        -59.69901109, -73.16815791],\n",
       "       [-31.59670027, -28.05956272, -30.40064515, ..., -17.67892896,\n",
       "        -22.51437818, -29.22333363],\n",
       "       [ 39.59967924,  38.58499099,  39.66795185, ...,  35.07206841,\n",
       "         37.2502028 ,  43.02494519],\n",
       "       ...,\n",
       "       [ 69.88955802,  24.5637892 ,  52.41854568, ..., 106.78796002,\n",
       "        102.79795509, 137.64734616],\n",
       "       [ 63.90011689,  -3.02341535,  14.90178861, ..., 150.59374912,\n",
       "        139.59818744, 164.26619786],\n",
       "       [-19.09647781, -47.44984823, -61.35651896, ...,  -1.97052429,\n",
       "         -7.0484108 ,   8.76181162]])"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12-lead ECG (np array)\n",
    "current_train[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: ECG Classification Model Pipeline\n",
    "\n",
    "Now that our data is preprocessed, we can begin working on the Model Pipeline itself. The ECG Classification Model Pipeline will consist of three components:\n",
    "\n",
    "1. `TextEncoder()` class\n",
    "\n",
    "2. `ECGEncoder()` class\n",
    "\n",
    "3. `InstanceSelector()` class\n",
    "\n",
    "4. `CLIPModel()` class\n",
    "\n",
    "An overview and outline of each of these components can be found below in their respective subsections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextEncoder()\n",
    "\n",
    "Create a class, ```TextEncoder()``` that is used to convert the description of the (dx_modality) diagnosis class into embeddings using the ClinicalBERT model.\n",
    "\n",
    "- Input should be a concatenated using comma or blank space string of diagnoses/dx_modality per ECG signal.\n",
    "- Use processed CSV files (dx_modality vs dx_modality, age, etc together)\n",
    "- Frozen weights (since it's already pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "        self.model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "\n",
    "        # Add embed_dim attribute\n",
    "        self.embed_dim = self.model.config.hidden_size\n",
    "\n",
    "    def encode(self, text_list):\n",
    "        # Check if text_list is a string representation of a list\n",
    "        if isinstance(text_list, str):\n",
    "            text_list = ast.literal_eval(text_list)\n",
    "        # Convert list of strings to a single string\n",
    "        text = ', '.join(text_list)\n",
    "        # Tokenize text\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        # Get embeddings from ClinicalBERT model\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.model(**inputs).last_hidden_state\n",
    "        # Average the embeddings to get single vector per each input\n",
    "        embeddings = torch.mean(embeddings, dim=1)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECGEncoder()\n",
    "\n",
    "- Input is ECG signal, output will be embeddings of ECG signal\n",
    "- This is going to be model in model.py\n",
    "- Model weights are updated iteratively\n",
    "- optimizer = torch.optim.Adam(clip_model.ECGEncoder.parameters())\n",
    "\n",
    "**Current Tasks:**\n",
    "\n",
    "- Change number of layers of fully connected layer 2 to 768 out_channels\n",
    "- Alternatively look into getting rid of the second fully connected layer. \n",
    "- Shifting from 128 --> 768 can cause loss of information. \n",
    "- Update all layers after layer 7 as follows:  \n",
    "    - ```self.conv7 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)```\n",
    "    - ```self.bn7 = nn.BatchNorm1d(512)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECGEncoder, self).__init__()\n",
    "\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv1d(in_channels=12, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Layer 3\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Layer 4\n",
    "        self.conv4 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm1d(128)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Layer 5\n",
    "        self.conv5 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.pool5 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Layer 6\n",
    "        self.conv6 = nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm1d(512)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.pool6 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Layer 7\n",
    "        self.conv7 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm1d(512)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.pool7 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Layer 8\n",
    "        self.conv8 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn8 = nn.BatchNorm1d(512)\n",
    "        self.relu8 = nn.ReLU()\n",
    "        self.pool8 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Layer 9\n",
    "        self.conv9 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn9 = nn.BatchNorm1d(512)\n",
    "        self.relu9 = nn.ReLU()\n",
    "        self.pool9 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Layer 10\n",
    "        self.conv10 = nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn10 = nn.BatchNorm1d(512)\n",
    "        self.relu10 = nn.ReLU()\n",
    "        self.pool10 = nn.AvgPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully Connected Layer 1\n",
    "        self.fc1 = nn.Linear(512, 768)\n",
    "        self.relu11 = nn.ReLU()\n",
    "\n",
    "        # Add embed_dim attribute\n",
    "        self.embed_dim = 768\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Layer 4\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # Layer 5\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        # Layer 6\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.pool6(x)\n",
    "\n",
    "        # Layer 7\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.pool7(x)\n",
    "\n",
    "        # Layer 8\n",
    "        x = self.conv8(x)\n",
    "        x = self.bn8(x)\n",
    "        x = self.relu8(x)\n",
    "        x = self.pool8(x)\n",
    "\n",
    "        # Layer 9\n",
    "        x = self.conv9(x)\n",
    "        x = self.bn9(x)\n",
    "        x = self.relu9(x)\n",
    "        x = self.pool9(x)\n",
    "\n",
    "        # Layer 10\n",
    "        x = self.conv10(x)\n",
    "        x = self.bn10(x)\n",
    "        x = self.relu10(x)\n",
    "        x = self.pool10(x)\n",
    "\n",
    "        # Flatten the output of the convolutional layers\n",
    "        print(x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully Connected Layer 1\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu11(x) \n",
    "\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5252880 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# Count the parameters\n",
    "num_params = count_parameters(model)\n",
    "print(f'The model has {num_params} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 1])\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.3246, 0.0000, 0.0000, 0.7574, 0.1264, 0.3254,\n",
      "         0.0000, 0.0000, 0.1755, 0.5313, 0.4154, 0.0000, 0.0926, 0.2853, 0.6299,\n",
      "         0.2317, 0.0000, 0.0000, 0.0000, 0.0000, 0.3558, 0.5572, 0.1329, 0.0000,\n",
      "         0.5276, 0.1226, 0.0000, 0.0000, 0.2213, 0.0415, 0.2600, 0.0000, 0.3782,\n",
      "         0.0000, 0.3827, 0.1524, 0.0939, 0.1162, 0.0000, 0.0237, 0.0288, 0.2119,\n",
      "         0.0000, 0.1187, 0.0000, 0.0000, 0.0000, 0.0000, 0.0892, 0.1432, 0.0000,\n",
      "         0.1495, 0.0599, 0.1057, 0.0263, 0.0000, 0.0048, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.5135, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0515,\n",
      "         0.2335, 0.5067, 0.3218, 0.0000, 0.0813, 0.0132, 0.1410, 0.0000, 0.1216,\n",
      "         0.0000, 0.0000, 0.0000, 0.0298, 0.0000, 0.0919, 0.1550, 0.0845, 0.1031,\n",
      "         0.0178, 0.1158, 0.1857, 0.1335, 0.0000, 0.3484, 0.0887, 0.0000, 0.0000,\n",
      "         0.2712, 0.1413, 0.0000, 0.1247, 0.0000, 0.0000, 0.0000, 0.0000, 0.4725,\n",
      "         0.0000, 0.0000, 0.1906, 0.0902, 0.0682, 0.0000, 0.3429, 0.0000, 0.1123,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1075, 0.0000, 0.2063, 0.0277,\n",
      "         0.1786, 0.3027, 0.0000, 0.0000, 0.3063, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.3812, 0.0000, 0.1459, 0.4354, 0.2811, 0.0000,\n",
      "         0.6857, 0.6580, 0.2413, 0.5959, 0.0000, 0.2935, 0.0853, 0.3513, 0.2497,\n",
      "         0.4297, 0.1895, 0.0328, 0.0000, 0.0936, 0.3779, 0.3830, 0.0000, 0.2056,\n",
      "         0.0000, 0.1476, 0.0000, 0.1367, 0.0000, 0.0000, 0.5176, 0.2867, 0.2092,\n",
      "         0.1170, 0.0000, 0.2685, 0.1262, 0.0366, 0.0000, 0.0000, 0.2521, 0.0000,\n",
      "         0.2207, 0.0610, 0.3299, 0.3150, 0.0000, 0.0000, 0.0712, 0.0000, 0.0000,\n",
      "         0.2579, 0.3830, 0.0000, 0.0000, 0.1931, 0.0297, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0225, 0.0000, 0.0655, 0.0000, 0.0000, 0.0000, 0.0000, 0.2884,\n",
      "         0.0000, 0.1788, 0.0000, 0.0000, 0.4883, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2119, 0.0000, 0.0141, 0.3084, 0.1411, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0175, 0.0000, 0.2058, 0.0000, 0.0000, 0.0000,\n",
      "         0.0369, 0.2366, 0.0000, 0.0000, 0.0000, 0.1844, 0.0256, 0.0000, 0.2569,\n",
      "         0.0487, 0.0000, 0.4670, 0.2606, 0.2647, 0.0000, 0.0292, 0.2771, 0.0295,\n",
      "         0.0000, 0.0000, 0.2007, 0.0000, 0.0000, 0.0000, 0.0000, 0.1077, 0.3089,\n",
      "         0.1875, 0.0889, 0.0000, 0.1646, 0.0414, 0.0000, 0.0000, 0.0856, 0.3535,\n",
      "         0.3553, 0.2951, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6770, 0.1454,\n",
      "         0.0000, 0.0000, 0.4361, 0.0043, 0.1365, 0.3555, 0.0000, 0.0000, 0.0000,\n",
      "         0.0755, 0.0000, 0.0545, 0.0000, 0.0171, 0.0231, 0.1879, 0.4053, 0.0000,\n",
      "         0.0240, 0.0000, 0.0000, 0.2920, 0.1603, 0.2940, 0.0000, 0.0212, 0.0000,\n",
      "         0.5584, 0.0000, 0.0000, 0.1586, 0.2242, 0.0000, 0.1917, 0.0000, 0.3974,\n",
      "         0.0000, 0.0000, 0.2205, 0.0000, 0.0364, 0.5522, 0.3853, 0.5817, 0.0000,\n",
      "         0.1396, 0.1865, 0.0000, 0.0000, 0.2067, 0.0000, 0.0293, 0.0000, 0.0000,\n",
      "         0.0936, 0.0000, 0.0000, 0.0000, 0.2842, 0.0000, 0.0817, 0.0000, 0.2455,\n",
      "         0.0416, 0.0000, 0.0000, 0.0000, 0.1079, 0.1169, 0.0000, 0.0000, 0.1778,\n",
      "         0.1152, 0.0000, 0.1540, 0.0000, 0.4896, 0.0000, 0.0000, 0.2782, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.2270, 0.0000, 0.0000, 0.2839, 0.4928, 0.0000,\n",
      "         0.0000, 0.1116, 0.1548, 0.1057, 0.0000, 0.1434, 0.0000, 0.1793, 0.2412,\n",
      "         0.0097, 0.5134, 0.0864, 0.0000, 0.0000, 0.0000, 0.0000, 0.5801, 0.0000,\n",
      "         0.0000, 0.2187, 0.0000, 0.0000, 0.0000, 0.2778, 0.0614, 0.0000, 0.0000,\n",
      "         0.1699, 0.1433, 0.0856, 0.4774, 0.0000, 0.0000, 0.1315, 0.0000, 0.1430,\n",
      "         0.0000, 0.4275, 0.3506, 0.1566, 0.0000, 0.0000, 0.1091, 0.5538, 0.0416,\n",
      "         0.0000, 0.0509, 0.1312, 0.0561, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.4105, 0.0980, 0.2305, 0.2505, 0.1971, 0.0000, 0.0000, 0.1849,\n",
      "         0.5461, 0.1446, 0.1569, 0.0000, 0.0804, 0.1268, 0.1304, 0.0000, 0.0000,\n",
      "         0.0150, 0.0000, 0.4317, 0.0000, 0.0922, 0.1991, 0.2155, 0.1153, 0.1674,\n",
      "         0.0000, 0.4312, 0.1033, 0.0000, 0.3472, 0.3090, 0.2631, 0.0000, 0.0000,\n",
      "         0.0944, 0.2881, 0.0000, 0.2947, 0.0000, 0.0069, 0.2277, 0.0000, 0.1970,\n",
      "         0.6133, 0.0000, 0.0000, 0.1412, 0.0000, 0.0000, 0.0000, 0.0000, 0.1033,\n",
      "         0.0000, 0.1587, 0.0000, 0.2907, 0.4292, 0.0000, 0.1104, 0.0000, 0.3412,\n",
      "         0.0000, 0.1780, 0.0000, 0.0000, 0.0033, 0.1637, 0.0129, 0.0000, 0.0000,\n",
      "         0.5692, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0961, 0.0000, 0.1804,\n",
      "         0.0000, 0.3739, 0.0191, 0.0000, 0.3693, 0.0238, 0.0000, 0.2943, 0.0000,\n",
      "         0.0000, 0.1920, 0.0000, 0.0000, 0.0526, 0.0000, 0.0000, 0.1420, 0.0804,\n",
      "         0.2181, 0.0000, 0.3587, 0.1242, 0.4713, 0.2699, 0.0060, 0.0587, 0.2706,\n",
      "         0.0000, 0.1348, 0.0000, 0.3578, 0.3837, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2581, 0.0045, 0.0000, 0.2075, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1374, 0.0000, 0.0000, 0.1689, 0.1999, 0.2668, 0.0000, 0.0000, 0.6730,\n",
      "         0.0000, 0.1434, 0.0000, 0.0000, 0.2755, 0.4029, 0.0000, 0.3788, 0.0000,\n",
      "         0.0000, 0.0000, 0.0111, 0.0000, 0.2713, 0.0000, 0.0000, 0.3260, 0.0000,\n",
      "         0.0378, 0.0000, 0.0810, 0.0000, 0.0000, 0.3387, 0.0000, 0.3541, 0.0882,\n",
      "         0.0000, 0.1808, 0.0000, 0.0000, 0.0000, 0.1698, 0.0000, 0.0292, 0.2451,\n",
      "         0.0487, 0.0184, 0.0375, 0.0412, 0.3237, 0.3448, 0.0000, 0.0000, 0.0000,\n",
      "         0.4878, 0.0000, 0.5152, 0.0000, 0.0000, 0.1066, 0.0035, 0.4667, 0.0000,\n",
      "         0.0992, 0.1010, 0.0000, 0.0063, 0.1362, 0.0000, 0.0000, 0.0000, 0.1052,\n",
      "         0.2666, 0.3457, 0.3801, 0.0201, 0.4068, 0.0891, 0.0000, 0.0000, 0.0000,\n",
      "         0.2473, 0.0000, 0.0000, 0.0000, 0.3756, 0.1863, 0.0000, 0.0000, 0.0708,\n",
      "         0.0000, 0.0771, 0.1160, 0.1573, 0.0000, 0.3285, 0.0637, 0.1594, 0.0000,\n",
      "         0.0000, 0.3665, 0.1348, 0.0000, 0.0000, 0.0000, 0.4479, 0.3461, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0021, 0.3803, 0.4253, 0.0000, 0.0296,\n",
      "         0.0000, 0.1234, 0.0000, 0.0000, 0.3541, 0.0114, 0.3711, 0.0000, 0.1929,\n",
      "         0.1868, 0.0254, 0.1042, 0.0000, 0.3109, 0.0000, 0.0000, 0.5115, 0.2830,\n",
      "         0.0000, 0.0000, 0.1639, 0.0000, 0.0000, 0.0000, 0.2709, 0.3378, 0.4643,\n",
      "         0.0000, 0.3340, 0.0380, 0.1423, 0.0000, 0.4036, 0.3739, 0.0000, 0.0000,\n",
      "         0.4162, 0.0000, 0.0000, 0.0767, 0.0389, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.7049, 0.0022, 0.0000, 0.0000, 0.4650, 0.0431, 0.0000, 0.0000,\n",
      "         0.0000, 0.3163, 0.0763, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.2377, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1197, 0.0000, 0.0000, 0.0000, 0.0000, 0.0877, 0.0000, 0.0000, 0.2052,\n",
      "         0.0000, 0.2009, 0.0864, 0.0136, 0.1905, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0767, 0.0000, 0.8271, 0.3752, 0.0000, 0.0178, 0.3534, 0.0689,\n",
      "         0.0000, 0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = ECGEncoder()\n",
    "\n",
    "# Convert the numpy array to a PyTorch tensor\n",
    "input_data = torch.from_numpy(current_train[0][1]).float()\n",
    "\n",
    "# Add an extra dimension to the tensor to represent the batch size\n",
    "input_data = input_data.unsqueeze(0)\n",
    "\n",
    "# Pass the tensor through the model\n",
    "output = model(input_data)\n",
    "\n",
    "# Print the output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 1])\n",
      "tensor([[0.0222, 0.0000, 0.0000, 0.0150, 0.0000, 0.0205, 0.0534, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0083, 0.0385, 0.0030, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0302, 0.0000, 0.0000, 0.0000, 0.0134, 0.0522, 0.0000,\n",
      "         0.0099, 0.0000, 0.0171, 0.0114, 0.0000, 0.0000, 0.0251, 0.0000, 0.0000,\n",
      "         0.0000, 0.0312, 0.0000, 0.0310, 0.0000, 0.0000, 0.0000, 0.0000, 0.0012,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0167, 0.0300, 0.0166, 0.0078,\n",
      "         0.0000, 0.0404, 0.0335, 0.0000, 0.0000, 0.0000, 0.0042, 0.0000, 0.0000,\n",
      "         0.0301, 0.0000, 0.0000, 0.0000, 0.0050, 0.0107, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0435, 0.0109, 0.0334, 0.0483, 0.0013,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0119, 0.0000, 0.0191, 0.0441, 0.0000,\n",
      "         0.0000, 0.0048, 0.0000, 0.0000, 0.0260, 0.0000, 0.0000, 0.0228, 0.0000,\n",
      "         0.0000, 0.0426, 0.0000, 0.0246, 0.0000, 0.0000, 0.0000, 0.0000, 0.0438,\n",
      "         0.0235, 0.0000, 0.0050, 0.0000, 0.0000, 0.0000, 0.0000, 0.0180, 0.0400,\n",
      "         0.0000, 0.0239, 0.0000, 0.0000, 0.0000, 0.0216, 0.0000, 0.0000, 0.0000,\n",
      "         0.0212, 0.0000, 0.0431, 0.0000, 0.0126, 0.0127, 0.0000, 0.0000, 0.0216,\n",
      "         0.0000, 0.0000, 0.0000, 0.0211, 0.0000, 0.0038, 0.0111, 0.0205, 0.0176,\n",
      "         0.0289, 0.0000, 0.0000, 0.0000, 0.0350, 0.0189, 0.0000, 0.0228, 0.0071,\n",
      "         0.0195, 0.0000, 0.0000, 0.0209, 0.0000, 0.0049, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0267, 0.0000, 0.0000, 0.0142, 0.0171, 0.0106, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0352, 0.0040, 0.0000, 0.0000, 0.0019,\n",
      "         0.0000, 0.0018, 0.0022, 0.0000, 0.0000, 0.0000, 0.0328, 0.0295, 0.0135,\n",
      "         0.0448, 0.0016, 0.0000, 0.0169, 0.0305, 0.0133, 0.0266, 0.0137, 0.0231,\n",
      "         0.0000, 0.0189, 0.0000, 0.0562, 0.0000, 0.0095, 0.0230, 0.0189, 0.0444,\n",
      "         0.0000, 0.0331, 0.0132, 0.0035, 0.0079, 0.0000, 0.0000, 0.0184, 0.0000,\n",
      "         0.0000, 0.0000, 0.0383, 0.0000, 0.0235, 0.0000, 0.0000, 0.0154, 0.0154,\n",
      "         0.0000, 0.0049, 0.0119, 0.0000, 0.0082, 0.0461, 0.0041, 0.0000, 0.0303,\n",
      "         0.0000, 0.0031, 0.0000, 0.0283, 0.0000, 0.0000, 0.0298, 0.0000, 0.0305,\n",
      "         0.0000, 0.0000, 0.0166, 0.0000, 0.0311, 0.0081, 0.0000, 0.0270, 0.0000,\n",
      "         0.0000, 0.0250, 0.0079, 0.0053, 0.0000, 0.0096, 0.0170, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0096, 0.0165, 0.0357, 0.0000, 0.0000, 0.0000, 0.0407,\n",
      "         0.0000, 0.0488, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0442, 0.0501,\n",
      "         0.0000, 0.0166, 0.0404, 0.0000, 0.0029, 0.0000, 0.0000, 0.0000, 0.0210,\n",
      "         0.0113, 0.0201, 0.0304, 0.0187, 0.0000, 0.0135, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0148, 0.0000, 0.0167, 0.0000, 0.0400, 0.0391, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0237, 0.0000, 0.0013, 0.0340, 0.0041, 0.0443,\n",
      "         0.0282, 0.0057, 0.0419, 0.0104, 0.0000, 0.0362, 0.0019, 0.0465, 0.0042,\n",
      "         0.0259, 0.0000, 0.0000, 0.0000, 0.0000, 0.0139, 0.0000, 0.0000, 0.0370,\n",
      "         0.0000, 0.0000, 0.0282, 0.0000, 0.0156, 0.0000, 0.0236, 0.0000, 0.0397,\n",
      "         0.0000, 0.0003, 0.0000, 0.0037, 0.0296, 0.0324, 0.0000, 0.0327, 0.0167,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0423, 0.0182, 0.0000, 0.0000, 0.0264,\n",
      "         0.0000, 0.0000, 0.0531, 0.0224, 0.0077, 0.0000, 0.0417, 0.0000, 0.0231,\n",
      "         0.0000, 0.0350, 0.0078, 0.0101, 0.0360, 0.0107, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0299, 0.0000, 0.0068, 0.0386, 0.0227, 0.0379, 0.0000, 0.0000,\n",
      "         0.0000, 0.0010, 0.0000, 0.0000, 0.0184, 0.0000, 0.0116, 0.0231, 0.0259,\n",
      "         0.0000, 0.0366, 0.0144, 0.0000, 0.0000, 0.0000, 0.0259, 0.0000, 0.0201,\n",
      "         0.0000, 0.0168, 0.0214, 0.0000, 0.0000, 0.0000, 0.0026, 0.0531, 0.0000,\n",
      "         0.0000, 0.0058, 0.0000, 0.0000, 0.0000, 0.0000, 0.0377, 0.0000, 0.0000,\n",
      "         0.0329, 0.0171, 0.0000, 0.0283, 0.0000, 0.0214, 0.0000, 0.0399, 0.0081,\n",
      "         0.0118, 0.0246, 0.0000, 0.0324, 0.0000, 0.0268, 0.0000, 0.0000, 0.0000,\n",
      "         0.0063, 0.0000, 0.0341, 0.0198, 0.0000, 0.0000, 0.0085, 0.0000, 0.0269,\n",
      "         0.0000, 0.0523, 0.0000, 0.0000, 0.0000, 0.0433, 0.0000, 0.0000, 0.0254,\n",
      "         0.0000, 0.0169, 0.0375, 0.0434, 0.0000, 0.0246, 0.0436, 0.0000, 0.0000,\n",
      "         0.0232, 0.0231, 0.0000, 0.0300, 0.0050, 0.0000, 0.0011, 0.0099, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0489, 0.0000, 0.0398, 0.0000, 0.0021,\n",
      "         0.0309, 0.0000, 0.0000, 0.0049, 0.0065, 0.0000, 0.0000, 0.0000, 0.0020,\n",
      "         0.0171, 0.0218, 0.0335, 0.0239, 0.0000, 0.0000, 0.0054, 0.0000, 0.0000,\n",
      "         0.0313, 0.0254, 0.0000, 0.0000, 0.0281, 0.0003, 0.0000, 0.0147, 0.0054,\n",
      "         0.0000, 0.0000, 0.0000, 0.0050, 0.0344, 0.0000, 0.0319, 0.0190, 0.0000,\n",
      "         0.0294, 0.0000, 0.0000, 0.0023, 0.0314, 0.0000, 0.0306, 0.0000, 0.0135,\n",
      "         0.0000, 0.0119, 0.0000, 0.0354, 0.0277, 0.0000, 0.0396, 0.0000, 0.0478,\n",
      "         0.0000, 0.0163, 0.0000, 0.0448, 0.0000, 0.0057, 0.0003, 0.0154, 0.0389,\n",
      "         0.0296, 0.0000, 0.0000, 0.0436, 0.0000, 0.0279, 0.0000, 0.0000, 0.0452,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0063, 0.0241, 0.0418, 0.0072,\n",
      "         0.0000, 0.0000, 0.0448, 0.0263, 0.0195, 0.0000, 0.0031, 0.0135, 0.0046,\n",
      "         0.0178, 0.0000, 0.0000, 0.0261, 0.0000, 0.0000, 0.0000, 0.0349, 0.0032,\n",
      "         0.0307, 0.0000, 0.0010, 0.0198, 0.0000, 0.0043, 0.0000, 0.0000, 0.0151,\n",
      "         0.0209, 0.0000, 0.0000, 0.0000, 0.0089, 0.0373, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0349, 0.0000, 0.0000, 0.0000, 0.0202, 0.0337, 0.0000,\n",
      "         0.0000, 0.0086, 0.0000, 0.0374, 0.0000, 0.0444, 0.0492, 0.0016, 0.0000,\n",
      "         0.0339, 0.0341, 0.0067, 0.0000, 0.0520, 0.0000, 0.0000, 0.0000, 0.0253,\n",
      "         0.0325, 0.0165, 0.0366, 0.0228, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0206, 0.0000, 0.0111, 0.0024, 0.0000, 0.0000, 0.0333, 0.0000,\n",
      "         0.0299, 0.0054, 0.0000, 0.0141, 0.0000, 0.0306, 0.0020, 0.0000, 0.0000,\n",
      "         0.0324, 0.0000, 0.0000, 0.0262, 0.0035, 0.0414, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0075, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0540, 0.0000, 0.0000, 0.0321, 0.0438, 0.0392, 0.0000, 0.0203, 0.0170,\n",
      "         0.0113, 0.0000, 0.0027, 0.0221, 0.0000, 0.0379, 0.0000, 0.0386, 0.0000,\n",
      "         0.0197, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0069,\n",
      "         0.0463, 0.0288, 0.0000, 0.0000, 0.0000, 0.0000, 0.0364, 0.0076, 0.0091,\n",
      "         0.0407, 0.0226, 0.0351, 0.0203, 0.0000, 0.0459, 0.0000, 0.0000, 0.0378,\n",
      "         0.0000, 0.0464, 0.0285, 0.0000, 0.0000, 0.0000, 0.0000, 0.0335, 0.0000,\n",
      "         0.0332, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0314, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0348, 0.0257,\n",
      "         0.0000, 0.0320, 0.0355, 0.0000, 0.0309, 0.0365, 0.0000, 0.0138, 0.0165,\n",
      "         0.0000, 0.0107, 0.0000, 0.0330, 0.0147, 0.0000, 0.0324, 0.0047, 0.0000,\n",
      "         0.0269, 0.0386, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Pass the data through the model\n",
    "output = model(input_data)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIPModel\n",
    "\n",
    "The final component of the Model Pipeline is to create a `ClIPModel` class which takes `TextEncoder` and `ECGEncoder` to train the final model with contrastive loss. \n",
    "\n",
    "```\n",
    "# image_encoder - ResNet or Vision Transformer\n",
    "# text_encoder - CBOW or Text Transformer\n",
    "# I[n, h, w, c] - minibatch of aligned images\n",
    "# T[n, l] - minibatch of aligned texts\n",
    "# W_i[d_i, d_e] - learned proj of image to embed\n",
    "# W_t[d_t, d_e] - learned proj of text to embed\n",
    "# t - learned temperature parameter\n",
    "# extract feature representations of each modality\n",
    "I_f = image_encoder(I) #[n, d_i]\n",
    "T_f = text_encoder(T) #[n, d_t]\n",
    "# joint multimodal embedding [n, d_e]\n",
    "I_e = l2_normalize(np.dot(I_f, W_i), axis=1)\n",
    "T_e = l2_normalize(np.dot(T_f, W_t), axis=1)\n",
    "# scaled pairwise cosine similarities [n, n]\n",
    "logits = np.dot(I_e, T_e.T) * np.exp(t)\n",
    "# symmetric loss function\n",
    "labels = np.arange(n)\n",
    "loss_i = cross_entropy_loss(logits, labels, axis=0)\n",
    "loss_t = cross_entropy_loss(logits, labels, axis=1)\n",
    "loss = (loss_i + loss_t)/2\n",
    "Figure 3. Numpy-like pseudocode for the core of an implementation of CLIP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPModel(nn.Module):\n",
    "    def __init__(self, text_encoder, ecg_encoder, embed_dim, temperature):\n",
    "        super(CLIPModel, self).__init__()\n",
    "        self.text_encoder = text_encoder\n",
    "        self.ecg_encoder = ecg_encoder\n",
    "        self.temperature = temperature\n",
    "        self.W_i = nn.Linear(ecg_encoder.embed_dim, embed_dim)\n",
    "        self.W_t = nn.Linear(text_encoder.embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, ecgs, texts):\n",
    "        # Extract feature representations of each modality\n",
    "        I_f = self.ecg_encoder(ecgs)  # [n, d_i]\n",
    "        T_f = self.text_encoder.encode(texts)  # [n, d_t]\n",
    "\n",
    "        # Joint multimodal embedding [n, d_e]\n",
    "        I_e = F.normalize(self.W_i(I_f), dim=1)\n",
    "        T_e = F.normalize(self.W_t(T_f), dim=1)\n",
    "\n",
    "        print(f\"I_e shape: {I_e.shape}\")\n",
    "        print(f\"T_e shape: {T_e.shape}\")\n",
    "\n",
    "        # Scaled pairwise cosine similarities [n, n]\n",
    "        logits = torch.matmul(I_e, T_e.t()) / self.temperature\n",
    "\n",
    "        # Symmetric loss function\n",
    "        labels = torch.arange(len(ecgs)).to(ecgs.device)\n",
    "        loss_i = F.cross_entropy(logits, labels)\n",
    "        loss_t = F.cross_entropy(logits.t(), labels)\n",
    "        loss = (loss_i + loss_t) / 2\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the encoders and the model\n",
    "CLIP_model = CLIPModel(text_encoder, ecg_encoder, embed_dim=512, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 50 random indices\n",
    "indices = random.sample(range(len(current_train)), 50)\n",
    "\n",
    "# Extract the samples at these indices\n",
    "texts = [current_train[i][0] for i in indices]\n",
    "ecgs = [current_train[i][1] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to tensors\n",
    "texts = [', '.join(text) for text in texts]  # Convert list of strings to a single string for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_ecg(ecg, new_length=1280):\n",
    "    # Get the current length of the ECG\n",
    "    current_length = ecg.shape[1]\n",
    "\n",
    "    # Resample the ECG\n",
    "    resampled_ecg = signal.resample(ecg, new_length, axis=1)\n",
    "\n",
    "    return resampled_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280), (12, 1280)]\n"
     ]
    }
   ],
   "source": [
    "# Resample all ECGs\n",
    "resampled_ecgs = [resample_ecg(ecg) for ecg in ecgs]\n",
    "\n",
    "# Print the shapes of the resampled ECGs\n",
    "shapes = [ecg.shape for ecg in resampled_ecgs]\n",
    "print(shapes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
