{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import resample\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import ast\n",
    "import scipy.io as sio\n",
    "from torch.utils.data import random_split\n",
    "from torch.nn.functional import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('C:/Users/navme/Desktop/ECG_Project/PyFiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updated PhysioNetDataset Class \n",
    "\n",
    "- Update the ```PhysioNetDataset``` class such that instead of header_info --> return header_info['Dx']. Then convert the Dx code to string input for TextEncoder(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysioNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset_path, train=False):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.dataset_path = [path for path in self.dataset_path if \"index.html\" not in path]\n",
    "        self.train = train\n",
    "        self.file_list = os.listdir(dataset_path)\n",
    "        self._hea_files = []\n",
    "        self._mat_files = []\n",
    "        self._indices_files = []\n",
    "        self._hea_files_path = []\n",
    "        self._mat_files_path = []\n",
    "\n",
    "        self.file_PATHS = []  # Directory to main database folders\n",
    "        self.data_files = []  # Directory to data files\n",
    "\n",
    "        # Validation Case: PTB Databases only\n",
    "        if self.train == False:\n",
    "            validation_datasets = ['ptb', 'ptb-xl']\n",
    "            for file in os.listdir(dataset_path):\n",
    "                if file in validation_datasets:\n",
    "                    file_path = os.path.join(dataset_path, file)\n",
    "                    file_path = file_path.replace('\\\\', '/')\n",
    "                    self.file_PATHS.append(file_path)\n",
    "\n",
    "        # Training Case: All Databases excluding PTB\n",
    "        else:\n",
    "            validation_datasets = ['ptb', 'ptb-xl']\n",
    "            for file in os.listdir(dataset_path):\n",
    "                if file not in validation_datasets:\n",
    "                    file_path = os.path.join(dataset_path, file)\n",
    "                    file_path = file_path.replace('\\\\', '/')\n",
    "                    self.file_PATHS.append(file_path)\n",
    "\n",
    "        for path in self.file_PATHS:\n",
    "            if os.path.isdir(path):\n",
    "                for sub_folder in os.listdir(path):\n",
    "                    sub_folder_path = os.path.join(path, sub_folder)\n",
    "                    sub_folder_path = sub_folder_path.replace('\\\\', '/')\n",
    "                    \n",
    "                    # Ignore index.html files\n",
    "                    if sub_folder_path.endswith('index.html'):\n",
    "                        self._indices_files.append(sub_folder_path)\n",
    "                    else:\n",
    "                        if os.path.isdir(sub_folder_path):\n",
    "                            for file in os.listdir(sub_folder_path):\n",
    "                                # Get all .hea files\n",
    "                                if file.endswith('.hea'):\n",
    "                                    file_path = os.path.join(sub_folder_path, file)\n",
    "                                    file_path = file_path.replace('\\\\', '/')\n",
    "                                    self._hea_files.append(file_path)\n",
    "                                    self._hea_files_path.append(file_path)\n",
    "                                # Get all .mat files\n",
    "                                elif file.endswith('.mat'):\n",
    "                                    file_path = os.path.join(sub_folder_path, file)\n",
    "                                    file_path = file_path.replace('\\\\', '/')\n",
    "                                    self._mat_files.append(file_path)\n",
    "                                    self._mat_files_path.append(file_path)\n",
    "\n",
    "    def resample_ecg(self, data, old_freq, new_freq=128):\n",
    "        # Calculate the duration of the signal\n",
    "        duration = len(data) / old_freq\n",
    "\n",
    "        # Calculate the number of points in the resampled signal\n",
    "        num_points = int(np.round(duration * new_freq))\n",
    "\n",
    "        # Resample the signal\n",
    "        resampled_data = resample(data, num_points)\n",
    "\n",
    "        return resampled_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, slice):\n",
    "            start, stop, step = index.indices(len(self))\n",
    "            return [self[i] for i in range(start, stop, step)]\n",
    "        # 1. Get .hea file\n",
    "        hea_file_path = self._hea_files[index]\n",
    "        with open(hea_file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        # Parse header information\n",
    "        # Initialize header information\n",
    "        header_info = {\n",
    "            'recording_number': lines[0].split()[0],\n",
    "            'recording_file': lines[0].split()[0] + '.mat',\n",
    "            'num_leads': int(lines[0].split()[1]),\n",
    "            'sampling_frequency': int(lines[0].split()[2]),\n",
    "            'num_samples': int(lines[0].split()[3]),\n",
    "            'leads_info': [],\n",
    "            'age': None,\n",
    "            'sex': None,\n",
    "            'dx': None,\n",
    "            'rx': None,\n",
    "            'hx': None,\n",
    "            'sx': None,\n",
    "        }\n",
    "\n",
    "        # Parse header information\n",
    "        for line in lines:\n",
    "            if line.startswith('# Age:'):\n",
    "                age_str = line.split(':')[1].strip()\n",
    "                header_info['age'] = int(age_str) if age_str != 'NaN' else None\n",
    "            elif line.startswith('# Sex:'):\n",
    "                header_info['sex'] = line.split(':')[1].strip()\n",
    "            elif line.startswith('# Dx:'):\n",
    "                header_info['dx'] = line.split(':')[1].strip().split(',')\n",
    "            elif line.startswith('# Rx:'):\n",
    "                header_info['rx'] = line.split(':')[1].strip()\n",
    "            elif line.startswith('# Hx:'):\n",
    "                header_info['hx'] = line.split(':')[1].strip()\n",
    "            elif line.startswith('# Sx:'):\n",
    "                header_info['sx'] = line.split(':')[1].strip()\n",
    "\n",
    "        for line in lines[1:header_info['num_leads']+1]:\n",
    "            adc_gain = line.split()[2].split('/')[0]\n",
    "            adc_gain = float(adc_gain.replace('(0)', ''))  # Remove '(0)' and convert to float\n",
    "            lead_info = {\n",
    "                'file': line.split()[0],\n",
    "                'adc_gain': adc_gain,\n",
    "                'units': line.split()[2].split('/')[1],\n",
    "                'adc_resolution': int(line.split()[3]),\n",
    "                'adc_zero': int(line.split()[4]),\n",
    "                'initial_value': int(line.split()[5]),\n",
    "                'checksum': int(line.split()[6]),\n",
    "                'lead_name': line.split()[7],\n",
    "            }\n",
    "            header_info['leads_info'].append(lead_info)\n",
    "\n",
    "        # 2. Get .mat file\n",
    "        twelve_lead_ecg = None\n",
    "        if index < len(self._mat_files):\n",
    "            mat_file_path = self._mat_files[index]\n",
    "            twelve_lead_ecg = sio.loadmat(mat_file_path)\n",
    "            \n",
    "            # Resample the ECG to 128 Hz\n",
    "            for lead in twelve_lead_ecg:\n",
    "                twelve_lead_ecg[lead] = self.resample_ecg(twelve_lead_ecg[lead], old_freq=header_info['sampling_frequency'])\n",
    "        else:\n",
    "            print(f\"MAT file for index {index} does not exist.\")\n",
    "        \n",
    "        return header_info, twelve_lead_ecg\n",
    "\n",
    "    def plot_record(self, index):\n",
    "        mat_file_path = self._mat_files[index]\n",
    "        data = sio.loadmat(mat_file_path)\n",
    "        fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(20, 15))\n",
    "\n",
    "        for i, ax in enumerate(axs.flat):\n",
    "            ax.plot(data['val'][i], linewidth=0.5)\n",
    "            ax.set_xlabel('Sample')\n",
    "            ax.set_ylabel('Amplitude')\n",
    "            ax.set_title(f'Lead {i+1}')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._hea_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
