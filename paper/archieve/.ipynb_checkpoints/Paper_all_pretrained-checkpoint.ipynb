{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c75479a-a32a-40c2-99e9-943071a57a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import utils, model, dataset, training, codes\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import os\n",
    "\n",
    "from lib import utils, model, dataset, training, codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa4042e-2e03-4f75-b2aa-373a347429c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.CFG({})\n",
    "config.seed = 43\n",
    "config.cache_path = 'cache'\n",
    "config.data_path = '/ayb/vol1/datasets/ecg_datasets/physionet.org/files/challenge-2021/1.0.3/training/ptb-xl'\n",
    "config.logs_path = 'results'\n",
    "config.models_path = 'results'\n",
    "config.test_size = 0.2\n",
    "config.valid_size = 0.25\n",
    "config.min_class_count = 200\n",
    "config.batch_size = 256\n",
    "config.num_workers = 12\n",
    "config.ecg_sr = 128\n",
    "config.window = 1280\n",
    "config.text_embedding_size = 768\n",
    "config.projection_dim = 256\n",
    "config.dropout = 0.15\n",
    "config.pretrained = True\n",
    "config.text_encoder_model = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "config.text_tokenizer = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "config.temperature = 10.0\n",
    "config.head_lr = 0.0001\n",
    "config.image_encoder_lr = 0.001\n",
    "config.device = 'cuda:2'\n",
    "config.epochs = 30\n",
    "config.max_length = 200\n",
    "config.ecg_encoder_channels = [32, 32, 64, 64, 128, 128, 256, 256]\n",
    "config.ecg_encoder_kernels = [7, 7, 5, 5, 3, 3, 3, 3]\n",
    "config.ecg_linear_size = 512\n",
    "config.ecg_embedding_size = 256\n",
    "config.ecg_channels = 12\n",
    "config.excluded_classes = ['abnormal QRS']\n",
    "config.train_required_classes = ['sinus rhythm']\n",
    "config.zero_shot_classes_size = 0.4\n",
    "config.ecg_encoder_model = 'ecglib_resnet1d50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc88d5c-624d-4ed6-97fa-8f160a1638df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/valid/test classes counts: 21 7 7 4\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "utils.set_seed(config.seed)\n",
    "df = utils.get_data_cached(config.data_path, codes.DECODE_DICT, config.cache_path + '/df.csv')\n",
    "\n",
    "train, test = train_test_split(df, test_size=config.test_size, random_state=config.seed)\n",
    "train, valid = train_test_split(train, test_size=config.valid_size, random_state=config.seed)\n",
    " \n",
    "train_classes =  utils.calsses_from_captions(train['label'].values, threshold=config.min_class_count)\n",
    "valid_classes =  utils.calsses_from_captions(valid['label'].values, threshold=config.min_class_count)\n",
    "test_classes = utils.calsses_from_captions(test['label'].values, threshold=config.min_class_count)\n",
    "\n",
    "train_classes = [class_ for class_ in train_classes if class_ not in config.excluded_classes]\n",
    "valid_classes = [class_ for class_ in valid_classes if class_ in train_classes]\n",
    "test_classes = [class_ for class_ in test_classes if class_ in train_classes]\n",
    "\n",
    "excluded = list()\n",
    "for class_ in config.train_required_classes:\n",
    "    if class_ in test_classes:\n",
    "        test_classes.remove(class_)\n",
    "        excluded.append(class_)\n",
    "        \n",
    "test_classes, zero_shot_classes = train_test_split(test_classes, test_size=config.zero_shot_classes_size, random_state=config.seed)\n",
    "\n",
    "test_classes += excluded\n",
    "\n",
    "train_classes = [class_ for class_ in train_classes if class_ not in zero_shot_classes]\n",
    "valid_classes = [class_ for class_ in valid_classes if class_ not in zero_shot_classes]\n",
    "\n",
    "train_classes = sorted(train_classes)\n",
    "valid_classes = sorted(valid_classes)\n",
    "test_classes = sorted(valid_classes)\n",
    "\n",
    "print('Train/valid/test classes counts:', len(train_classes), len(valid_classes), len(test_classes), len(zero_shot_classes))\n",
    "\n",
    "train['label'] = utils.remove_classes(zero_shot_classes, train['label'].to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "940f79f3-3a0f-45fc-9a18-088438f83adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 13101/13101 [00:01<00:00, 6742.83it/s]\n",
      "100%|█████████████████████████████████████| 4368/4368 [00:00<00:00, 8211.92it/s]\n",
      "Downloading: \"https://github.com/ispras/EcgLib/releases/download/v1.1.0/12_leads_resnet1d18_1AVB.pt\" to /home/kyegorov/.cache/torch/hub/checkpoints/12_leads_resnet1d18_1AVB_1_1_0.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/52 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (256x1 and 1024x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m hrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m epoch\n\u001b[1;32m     34\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 35\u001b[0m train_loss_meter, train_accuracy_meter \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m hrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_loss_meter\u001b[38;5;241m.\u001b[39mavg\n\u001b[1;32m     38\u001b[0m metrics \u001b[38;5;241m=\u001b[39m training\u001b[38;5;241m.\u001b[39mvalid_epoch(net, train_dl, train_classes, config) \n",
      "File \u001b[0;32m/data-lun/large/kyegorov/repos/students/HSE_MSK_Naive/ECG_Project/paper/lib/training.py:74\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, classes, config)\u001b[0m\n\u001b[1;32m     72\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     73\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 74\u001b[0m loss, image_embeddings, text_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     77\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/data-lun/large/kyegorov/virenvs/jupenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data-lun/large/kyegorov/virenvs/jupenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data-lun/large/kyegorov/repos/students/HSE_MSK_Naive/ECG_Project/paper/lib/model.py:216\u001b[0m, in \u001b[0;36mCLIPModel.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m--> 216\u001b[0m     image_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     text_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_to_embeddings(batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# Calculating the Loss\u001b[39;00m\n",
      "File \u001b[0;32m/data-lun/large/kyegorov/repos/students/HSE_MSK_Naive/ECG_Project/paper/lib/model.py:236\u001b[0m, in \u001b[0;36mCLIPModel.image_to_embeddings\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimage_to_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[1;32m    235\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_encoder(images)\n\u001b[0;32m--> 236\u001b[0m     image_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image_embeddings\n",
      "File \u001b[0;32m/data-lun/large/kyegorov/virenvs/jupenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data-lun/large/kyegorov/virenvs/jupenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data-lun/large/kyegorov/repos/students/HSE_MSK_Naive/ECG_Project/paper/lib/model.py:193\u001b[0m, in \u001b[0;36mProjectionHead.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 193\u001b[0m     projected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprojection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgelu(projected)\n\u001b[1;32m    195\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m/data-lun/large/kyegorov/virenvs/jupenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data-lun/large/kyegorov/virenvs/jupenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data-lun/large/kyegorov/virenvs/jupenv/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (256x1 and 1024x256)"
     ]
    }
   ],
   "source": [
    "config.train_classes = train_classes\n",
    "config.valid_classes = valid_classes\n",
    "config.test_classes = test_classes\n",
    "config.zero_shot_classes = zero_shot_classes\n",
    "\n",
    "train_ds = dataset.CLIP_ECG_Dataset(train, config)\n",
    "valid_ds = dataset.CLIP_ECG_Dataset(valid, config)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=config.batch_size, num_workers=config.num_workers, shuffle=True)\n",
    "valid_dl = torch.utils.data.DataLoader(valid_ds, batch_size=config.batch_size, num_workers=config.num_workers, shuffle=False)\n",
    "\n",
    "net = model.CLIPModel(config)\n",
    "net = net.to(config.device)\n",
    "params = [\n",
    "    {\"params\": net.image_encoder.parameters(), \"lr\": config.image_encoder_lr},\n",
    "    {\"params\": net.image_projection.parameters(), \"lr\": config.head_lr},\n",
    "    {\"params\": net.text_projection.parameters(), \"lr\": config.head_lr},\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(params)\n",
    "\n",
    "cfg = {k:v for k, v in config.__dict__.items() if not k.startswith('__')}\n",
    "cfg_hash = utils.generate_dict_hash(cfg)\n",
    "\n",
    "with open(f'{config.logs_path}/{cfg_hash}.cfg', 'w') as fp:\n",
    "    json.dump(cfg, fp)\n",
    "\n",
    "history = list()\n",
    "best_valid_score = 0.0\n",
    "for epoch in range(config.epochs):\n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    hrow = dict()\n",
    "    hrow['epoch'] = epoch\n",
    "    net.train()\n",
    "    train_loss_meter, train_accuracy_meter = training.train_epoch(net, train_dl, optimizer, train_classes, config)\n",
    "    hrow['train_loss'] = train_loss_meter.avg\n",
    "    \n",
    "    metrics = training.valid_epoch(net, train_dl, train_classes, config) \n",
    "    hrow.update({f'train_{key}': val for key, val in metrics.items()})\n",
    "    #hrow['train_mean_rocaucs'] = np.mean([val for key, val in metrics.items() if key.endswith('_rocauc') and val is not None])\n",
    "    #hrow['train_mean_praucs'] = np.mean([val for key, val in metrics.items() if key.endswith('_prauc') and val is not None])\n",
    "    print('Train:', hrow['train_mean_rocaucs'], hrow['train_mean_praucs'])\n",
    "    \n",
    "    metrics = training.valid_epoch(net, valid_dl, valid_classes, config) \n",
    "    hrow.update({f'valid_{key}': val for key, val in metrics.items()})\n",
    "    #hrow['valid_mean_rocaucs'] = np.mean([val for key, val in metrics.items() if key.endswith('_rocauc') and val is not None])\n",
    "    #hrow['valid_mean_praucs'] = np.mean([val for key, val in metrics.items() if key.endswith('_prauc') and val is not None])\n",
    "    print('Valid:', hrow['valid_mean_rocaucs'], hrow['valid_mean_praucs'])\n",
    "    \n",
    "    history.append(hrow)\n",
    "    pd.DataFrame(history).to_csv(config.logs_path + f'/{cfg_hash}.csv', index=False)\n",
    "\n",
    "    if hrow['valid_mean_rocaucs'] > best_valid_score:\n",
    "        best_valid_score = hrow['valid_mean_rocaucs']\n",
    "        torch.save(net.state_dict(), config.models_path + f'/{cfg_hash}.pt')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c047ecb-4e1a-4ec4-bd04-1b86c45a33e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = model.CLIPModel(config)\n",
    "net.load_state_dict(torch.load(config.models_path + f'/{cfg_hash}.pt', weights_only=True))\n",
    "net.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209de3f7-efb7-4c9c-b730-5e7553e80650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ds = dataset.CLIP_ECG_Dataset(test, config)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=config.batch_size, num_workers=config.num_workers, shuffle=True)\n",
    "metrics = training.valid_epoch(net, test_dl, config.test_classes, config) \n",
    "config.test_metrics = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738cbf2-ddf7-422c-bcbb-8fe1035c763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = training.valid_epoch(net, test_dl, config.zero_shot_classes, config) \n",
    "config.zero_shot_test_metrics = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200f4dff-39b4-4b54-a25e-45a81983f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78211724-5158-4321-bb44-87e0d1c60471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonprimary_code(x):\n",
    "    r = []\n",
    "    for cx in x:\n",
    "        for c in cx.split('+'):\n",
    "            if int(c) < 200 or int(c) >= 500:\n",
    "                if c not in r:\n",
    "                    r.append(c)\n",
    "    return r\n",
    "\n",
    "def codes_to_caption(codes):\n",
    "    classes = [description_dict[int(code)].lower() for code in codes]\n",
    "    caption = ', '.join(classes)\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59362959-658e-4c2d-9a3b-0fed1dddfa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/ayb/vol1/datasets/ecg_datasets/SPH'\n",
    "ecg_files = sorted(glob(f'{data_path}/records/*.h5'))\n",
    "df = pd.read_csv(f'{data_path}/metadata.csv')\n",
    "df['primary_codes'] = df['AHA_Code'].str.split(';').apply(remove_nonprimary_code)\n",
    "description_dict = pd.read_csv(f'{data_path}/code.csv').set_index('Code')['Description'].to_dict()\n",
    "df['label'] = df['primary_codes'].apply(codes_to_caption)\n",
    "df['ecg_file'] = df['ECG_ID'].apply(lambda x: f'{data_path}/records/{x}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b36fad-d01b-42e2-bd5b-56d61f3d431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ecg_file', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae375a6-582d-4cf0-91d1-abbab9b836f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.exp2_classes = utils.calsses_from_captions(df['label'].values, threshold=config.min_class_count)\n",
    "config.exp2_trained_classes = list(set(config.exp2_classes) & set(config.train_classes))\n",
    "config.exp2_untrained_classes = list(set(config.exp2_classes) - set(config.train_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d55c84d-f91e-433e-8fe8-7d44cee41e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b0c31-cac1-4288-a49f-d6a8ce2cf07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_ds = dataset.CLIP_ECG_Dataset(df, config)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=config.batch_size, num_workers=config.num_workers, shuffle=True)\n",
    "metrics = training.valid_epoch(net, test_dl, config.exp2_trained_classes, config) \n",
    "config.exp2_metrics_trained = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84cbf8-5cd5-4ab1-b2a5-78215b77da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = training.valid_epoch(net, test_dl, config.exp2_untrained_classes, config) \n",
    "config.exp2_metrics_untrained = metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3edceb5-6257-439f-b4ba-8f450c07afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79e53d-c979-495f-9ddb-082cf2a10be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.exp2_metrics_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4789aa-776f-418a-8118-567b7789c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.exp2_metrics_untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65224ee9-d3e4-472a-9290-aa1aa85ab02f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
